{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNs0qaL9IQXSD5FUjX7NFfW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romeo-the-rebel/COS711-Assignment-3/blob/main/COS711_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2Pqbc2y3s6Q"
      },
      "outputs": [],
      "source": [
        "# cell 1: essentials\n",
        "import os, glob, math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# optional: use astropy for accurate sky distances (recommended)\n",
        "try:\n",
        "    from astropy.coordinates import SkyCoord\n",
        "    import astropy.units as u\n",
        "    ASTROPY_AVAILABLE = True\n",
        "except Exception:\n",
        "    ASTROPY_AVAILABLE = False\n",
        "\n",
        "# paths (adjust if needed)\n",
        "labels_csv = \"labels.csv\"    # provided labels file (from assignment zip)\n",
        "test_csv   = \"test.csv\"\n",
        "typ_dir    = \"data/typical\"\n",
        "exo_dir    = \"data/exotic\"\n",
        "unl_dir    = \"data/unlabeled\"\n",
        "\n",
        "# helper to parse filenames like \"RA_DEC_...png\" (the actual separator may vary)\n",
        "def parse_coords_from_filename(fname):\n",
        "    # adapt to your filename pattern; this is a robust attempt\n",
        "    base = Path(fname).stem\n",
        "    parts = base.replace(\",\", \"_\").split(\"_\")\n",
        "    # find two tokens that parse as floats\n",
        "    floats = []\n",
        "    for p in parts:\n",
        "        try:\n",
        "            floats.append(float(p))\n",
        "            if len(floats)==2:\n",
        "                return floats[0], floats[1]\n",
        "        except:\n",
        "            continue\n",
        "    return None, None\n",
        "\n",
        "# load labels\n",
        "labels_df = pd.read_csv(labels_csv)\n",
        "# inspect\n",
        "labels_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 2: map images -> nearest label (using astropy if available)\n",
        "def nearest_label_for_image(img_path, labels_df):\n",
        "    ra_img, dec_img = parse_coords_from_filename(img_path)\n",
        "    if ra_img is None:\n",
        "        return None\n",
        "    if ASTROPY_AVAILABLE:\n",
        "        c_img = SkyCoord(ra=ra_img*u.deg, dec=dec_img*u.deg, unit=(u.deg,u.deg))\n",
        "        c_labels = SkyCoord(ra=labels_df['ra'].values*u.deg, dec=labels_df['dec'].values*u.deg, unit=(u.deg,u.deg))\n",
        "        sep = c_img.separation(c_labels).arcsec  # angular separation in arcsec\n",
        "        idx = np.argmin(sep)\n",
        "        return labels_df.iloc[idx]\n",
        "    else:\n",
        "        # fallback: Euclidean distance in coordinate space (works roughly if coords in degrees)\n",
        "        coords = labels_df[['ra','dec']].values\n",
        "        dists = np.sqrt((coords[:,0]-ra_img)**2 + (coords[:,1]-dec_img)**2)\n",
        "        idx = np.argmin(dists)\n",
        "        return labels_df.iloc[idx]\n",
        "\n",
        "# example: map typical dir\n",
        "typ_files = glob.glob(os.path.join(typ_dir, \"*\"))\n",
        "mapped = []\n",
        "for f in typ_files[:200]:   # don't iterate all now if large -- just test\n",
        "    lab = nearest_label_for_image(f, labels_df)\n",
        "    mapped.append((f, lab['label'] if lab is not None else None))\n",
        "\n",
        "mapped[:10]\n"
      ],
      "metadata": {
        "id": "_f7ejfYL4Kxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell: PyTorch dataloader skeleton\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# define the set of classes you'll predict (example; adapt to real labels)\n",
        "CLASSES = [\"Point\", \"FRI\", \"FRII\", \"Bent\", \"XRG\", \"ZRG\", \"ShouldBeDiscarded\", \"Other\", \"Exotic\"]\n",
        "class_to_idx = {c:i for i,c in enumerate(CLASSES)}\n",
        "\n",
        "def labels_to_multihot(label_list):\n",
        "    mh = np.zeros(len(CLASSES), dtype=np.float32)\n",
        "    for lab in label_list:\n",
        "        if lab in class_to_idx:\n",
        "            mh[class_to_idx[lab]] = 1.0\n",
        "    return mh\n",
        "\n",
        "train_transforms = T.Compose([\n",
        "    T.Resize((224,224)),\n",
        "    T.RandomRotation(30),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomVerticalFlip(),\n",
        "    T.ToTensor(),\n",
        "    # do normalization if using a pretrained model expecting ImageNet stats\n",
        "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class RadioDataset(Dataset):\n",
        "    def __init__(self, rows, transform=None):\n",
        "        # rows: list of (img_path, [list_of_labels])\n",
        "        self.rows = rows\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.rows)\n",
        "    def __getitem__(self, idx):\n",
        "        p, labs = self.rows[idx]\n",
        "        img = Image.open(p).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = torch.tensor(labels_to_multihot(labs))\n",
        "        return img, label\n",
        "\n",
        "# Example instantiation:\n",
        "# train_rows = [(path, [\"FRI\",\"Bent\"]), ...]\n",
        "# ds = RadioDataset(train_rows, transform=train_transforms)\n",
        "# dl = DataLoader(ds, batch_size=16, shuffle=True, num_workers=4)\n"
      ],
      "metadata": {
        "id": "-nf7BCMf4OR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def get_model(num_classes=len(CLASSES), backbone=\"resnet50\", pretrained=True):\n",
        "    if backbone==\"resnet50\":\n",
        "        m = models.resnet50(pretrained=pretrained)\n",
        "        nfeats = m.fc.in_features\n",
        "        m.fc = nn.Linear(nfeats, num_classes)\n",
        "    else:\n",
        "        # swap to EfficientNet, etc., as needed\n",
        "        m = models.resnet18(pretrained=pretrained)\n",
        "        nfeats = m.fc.in_features\n",
        "        m.fc = nn.Linear(nfeats, num_classes)\n",
        "    return m\n",
        "\n",
        "model = get_model()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()  # for multi-label\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n"
      ],
      "metadata": {
        "id": "eMXgJFpn4Vui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "    return total_loss / len(loader.dataset)\n"
      ],
      "metadata": {
        "id": "yp2627Fi4XBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wA662Jzw4a_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}